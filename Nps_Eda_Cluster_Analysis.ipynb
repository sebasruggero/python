{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "history_visible": true,
      "mount_file_id": "1bYCSW1_k-47pZT4C3sVrAIgeLi2qGS7v",
      "authorship_tag": "ABX9TyNOYdf+eqHs8Vu+QSLZrpzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebasruggero/python/blob/main/Nps_Eda_Cluster_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import gspread"
      ],
      "metadata": {
        "id": "1KoNvuxPNR_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montamos el drive de google para poder acceder al csv "
      ],
      "metadata": {
        "id": "ZgVt-_82QfuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou_yTpEZNP6s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accedemos al csv\n"
      ],
      "metadata": {
        "id": "5Y5dWVjbQmiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('gdrive/My Drive/DATA/npsData.csv')"
      ],
      "metadata": {
        "id": "1FJBPA_yNiwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicamos la funcion shape para ver la cantidad de registros y columnas que posee el dataframe\n"
      ],
      "metadata": {
        "id": "nvOxr9eyQq9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "7rHTAGsITcBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debemos identificar las columnas que poseen valores nulos para poder analizar el impacto de estas."
      ],
      "metadata": {
        "id": "VAG_LOrNQ1yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Gb8ZGPPSOFdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hacemos la funcion para determinar si corresponde a un Promoter, Passive o Detractor"
      ],
      "metadata": {
        "id": "86y2uDiCRKKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_nps(ltr):\n",
        "  if ltr == 9 or ltr == 10:\n",
        "    return \"Promoter\"\n",
        "  elif ltr == 8 or ltr == 9:\n",
        "    return \"Passive\"\n",
        "  elif ltr >= 0 or ltr <= 6:\n",
        "    return \"Detractor\"\n",
        "  else: \n",
        "    return 'invalid'"
      ],
      "metadata": {
        "id": "BBZxnJgBoEqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicamos la función"
      ],
      "metadata": {
        "id": "zMZTCriYRSVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['nps_group'] = df['ltr'].apply(categorize_nps)"
      ],
      "metadata": {
        "id": "xhdjT_Huo433"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R18pmOPWQbwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "W5k6eU6at5Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Realizamos las transformaciones en los tipos de datos "
      ],
      "metadata": {
        "id": "axxaNY6B04_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['ResponseDate'] = pd.to_datetime(df['ResponseDate'])\n",
        "df['caseID'] = df['caseID'].astype(str)\n",
        "df['assignToDisp'] = pd.to_numeric(df['assignToDisp'], errors='coerce')\n",
        "df['assignToDisp'] = df['assignToDisp'].round(2)\n",
        "df['mttr'] = pd.to_numeric(df['mttr'], errors='coerce')\n",
        "df['mttr'] = df['mttr'].round(2)\n",
        "df['ttrGros'] = pd.to_numeric(df['ttrGros'], errors='coerce')\n",
        "df['ttrGros'] = df['ttrGros'].round(2)\n",
        "df['ltr'] = df['ltr'].astype(float)\n"
      ],
      "metadata": {
        "id": "JdI66d8Uv-1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Gc0-It_2wUpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "irhapVYDrsSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "jtdL15n8Q8ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eda"
      ],
      "metadata": {
        "id": "Yea3ngV9t310"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_eda = df"
      ],
      "metadata": {
        "id": "_0IUxyKqTgOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estadísticas resumidas del dataframe\n",
        "print(df_eda.describe())"
      ],
      "metadata": {
        "id": "kFeR_c3Ot2_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribucion de los datos"
      ],
      "metadata": {
        "id": "ml2IMV2HWOu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot( x=\"ltr\", \n",
        "            data=df_eda, \n",
        "            hue='slaYield', \n",
        "            col=\"nps_group\", \n",
        "            kind=\"kde\",\n",
        "            col_wrap=3,\n",
        "            fill=True);"
      ],
      "metadata": {
        "id": "_0OB1qmYKElN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot( x=\"ltr\", \n",
        "            data=df_eda, \n",
        "            hue='slaYield', \n",
        "            col=\"supportSegment\", \n",
        "            kind=\"kde\",\n",
        "            col_wrap=5,\n",
        "            fill=True);\n",
        "\n"
      ],
      "metadata": {
        "id": "7WtkhT9IsLZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(df_eda, col='supportSegment', col_wrap=5)\n",
        "g.map(sns.histplot, 'ltr', kde=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nUJ_LGM0ReKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analisis de correlación"
      ],
      "metadata": {
        "id": "MInzevGxAI9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df_eda.corr()\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "rKNPLHnwwvxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df_eda.corr(), annot=True, cmap=sns.cubehelix_palette(as_cmap=True),square=True, linewidth=0.5);\n"
      ],
      "metadata": {
        "id": "LRN5oqwkAELQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### No se observan correlacion entre las variables de análisis en este caso LTR, MTTR, assignToDisp, ttrGross y slaYield"
      ],
      "metadata": {
        "id": "aWYhnSD4U4OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(df_eda, col='slaYield', col_wrap=3)\n",
        "g.map(sns.histplot, 'ltr', kde=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7l0guiZCB8WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Crear una columna de fecha\n",
        "df_eda['fecha'] = pd.to_datetime(df_eda['ResponseDate'])\n",
        "\n",
        "# Agregar una columna de mes y año\n",
        "df_eda['mes-año'] = df_eda['fecha'].dt.strftime('%m-%Y')\n",
        "\n",
        "# Crear una lista de meses ordenados\n",
        "order = ['10-2022', '11-2022', '12-2022', '01-2023', '02-2023', '03-2023']\n",
        "\n",
        "# Initialize the figure with a logarithmic x axis\n",
        "f, ax = plt.subplots(figsize=(20, 6))\n",
        "\n",
        "# Plot the orbital period with horizontal boxes\n",
        "sns.boxplot(x=\"mes-año\", y=\"ltr\", data=df_eda, order=order,\n",
        "            whis=[0, 100], width=.6, palette=\"vlag\")\n",
        "\n",
        "# Add in points to show each observation\n",
        "sns.stripplot(x=\"mes-año\", y=\"ltr\", data=df_eda, order=order,\n",
        "              size=4, color=\".3\", linewidth=0)\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIZWmc24SiHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analisis de boxplot \n"
      ],
      "metadata": {
        "id": "-ZY8zuVqsHtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Initialize the figure with a logarithmic x axis\n",
        "f, ax = plt.subplots(figsize=(20, 6))\n",
        "#ax.set_xscale(\"log\")\n",
        "\n",
        "\n",
        "# Plot the orbital period with horizontal boxes\n",
        "sns.boxplot(x=\"supportSegment\", y=\"ltr\", data=df_eda,\n",
        "            whis=[0, 100], width=.6, palette=\"vlag\")\n",
        "\n",
        "# Add in points to show each observation\n",
        "sns.stripplot(x=\"supportSegment\", y=\"ltr\", data=df_eda,\n",
        "              size=4, color=\".3\", linewidth=0)\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)"
      ],
      "metadata": {
        "id": "eJvwo0Hby15t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eda['escalation'] = pd.Categorical(df_eda['escalation'], categories=['Level 1', 'Level 2', 'TCAM', 'Level 4'])\n",
        "\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Initialize the figure with a logarithmic x axis\n",
        "f, ax = plt.subplots(figsize=(20, 6))\n",
        "#ax.set_xscale(\"log\")\n",
        "\n",
        "# Order the levels in the desired order\n",
        "df['escalation'] = pd.Categorical(df_eda['escalation'], categories=['Level 1', 'Level 2', 'TCAM', 'Level 4'])\n",
        "\n",
        "# Plot the orbital period with horizontal boxes\n",
        "sns.boxplot(x=\"escalation\", y=\"ltr\", data=df_eda,\n",
        "            whis=[0, 100], width=.3, palette=\"vlag\")\n",
        "\n",
        "# Add in points to show each observation\n",
        "sns.stripplot(x=\"escalation\", y=\"ltr\", data=df_eda,\n",
        "              size=4, color=\".1\", linewidth=0)\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "xH_JiVm3qwhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Initialize the figure with a logarithmic x axis\n",
        "f, ax = plt.subplots(figsize=(20, 6))\n",
        "#ax.set_xscale(\"log\")\n",
        "\n",
        "\n",
        "# Plot the orbital period with horizontal boxes\n",
        "sns.boxplot(x=\"slaYield\", y=\"ltr\", data=df_eda,\n",
        "            whis=[0, 100], width=.2, palette=\"vlag\")\n",
        "\n",
        "# Add in points to show each observation\n",
        "sns.stripplot(x=\"slaYield\", y=\"ltr\", data=df_eda,\n",
        "              size=3, color=\".3\", linewidth=0)\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)"
      ],
      "metadata": {
        "id": "DLIY-OfQXKLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma para la variable LTR\n",
        "sns.displot( x=\"ltr\", data=df_eda, hue='slaYield', kind=\"kde\", fill=True);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sBbLR4_rrblk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analisis de series de tiempo"
      ],
      "metadata": {
        "id": "Fym-uRixW99g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna de fecha en el índice del DataFrame\n",
        "df_eda.index = pd.to_datetime(df_eda['ResponseDate'])\n",
        "\n",
        "# Ordenar los datos por fecha\n",
        "df_eda = df_eda.sort_index()\n",
        "\n",
        "# Agrupar los datos por mes y calcular la tasa de éxito promedio y la desviación estándar para cada mes\n",
        "monthly_stats = df_eda.groupby(pd.Grouper(freq='M'))['ltr'].agg(['mean', 'std'])\n",
        "\n",
        "# Crear una figura con dos subplots: uno para la serie de tiempo de la tasa de éxito promedio y otro para la desviación estándar\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
        "\n",
        "# Graficar la serie de tiempo de la tasa de éxito promedio y la desviación estándar en sus respectivos subplots\n",
        "axs[0].plot(monthly_stats['mean'], color='blue')\n",
        "axs[0].set_ylabel('Tasa de éxito promedio')\n",
        "axs[1].plot(monthly_stats['std'], color='red')\n",
        "axs[1].set_ylabel('Desviación estándar')\n",
        "axs[1].set_xlabel('Fecha')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "RAz0Y5VCXCTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de agrupamiento con el algoritmo de clustering K-Means "
      ],
      "metadata": {
        "id": "bZXLjE1ZUXCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Definincion del Numero de Cluster"
      ],
      "metadata": {
        "id": "MoQVTF-A4D1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cargamos las librerias para calcular el numero de cluster del modelo\n",
        "from scipy.spatial import distance as sci_distance\n",
        "from sklearn import cluster as sk_cluster"
      ],
      "metadata": {
        "id": "IsM0ehTM2ioI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Filtramos un nuevo dataset de las variables numericas continuas\n",
        "derived_df = df.filter([\"mttr\", \"ttrGros\", \"ltr\"])"
      ],
      "metadata": {
        "id": "4VIdxoVX3A7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Aplicamos el algoritmo para determinar el numero optimo de cluster\n",
        "\n",
        "cdata = derived_df \n",
        "K = range(1, 20)\n",
        "KM = (sk_cluster.KMeans(n_clusters=k).fit(cdata) for k in K)\n",
        "centroids = (k.cluster_centers_ for k in KM)\n",
        "\n",
        "D_k = (sci_distance.cdist(cdata, cent, 'euclidean') for cent in centroids)\n",
        "dist = (np.min(D, axis=1) for D in D_k)\n",
        "avgWithinSS = [sum(d) / cdata.shape[0] for d in dist]\n",
        "plt.plot(K, avgWithinSS, 'b*-')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Average within-cluster sum of squares')\n",
        "plt.title('Elbow for KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o-DvTRKc1mWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster = df"
      ],
      "metadata": {
        "id": "_8wlQ5OyF7jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Seleccionar las variables a utilizar\n",
        "variables = [\"ltr\", \"ttrGros\"]\n",
        "\n",
        "# Filtrar el dataset por las variables seleccionadas\n",
        "X = df_cluster[variables]\n",
        "\n",
        "# Codificar las variables categóricas\n",
        "le = LabelEncoder()\n",
        "categorical_vars = [ \"caseType\", \"severity\", \"level3Detected\", \"escalation\", \"fixType\", \"rfoEnabled\", \"closeType\", \"clarifyName\", 'assignToDisp' , \"serviceid\", \"supportSegment\", \"nps_group\"]\n",
        "for var in categorical_vars:\n",
        "    X[var] = le.fit_transform(df_cluster[var].astype(str))\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Definir el modelo de clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=111)\n",
        "\n",
        "# Entrenar el modelo\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Agregar la columna con la etiqueta del cluster asignado a cada registro\n",
        "df[\"cluster_label\"] = kmeans.labels_\n",
        "\n",
        "# Calcular la tasa de éxito por cluster\n",
        "success_rate = df_cluster.groupby(\"cluster_label\")[\"ltr\"].mean()\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Tasa de éxito por cluster:\\n\", success_rate)\n"
      ],
      "metadata": {
        "id": "U5tdIRy5XpI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster['cluster_label'] = kmeans.labels_\n",
        "grupos = df_cluster.groupby('cluster_label')\n",
        "for label, grupo in grupos:\n",
        "    print('Grupo {}: {} proyectos'.format(label, len(grupo)))\n",
        "    print(grupo[[\"caseType\", \"severity\", \"level3Detected\", \"escalation\", \"fixType\", \"rfoEnabled\", \"closeType\", \"clarifyName\", 'assignToDisp' , \"serviceid\", \"supportSegment\", \"nps_group\"]].head())\n"
      ],
      "metadata": {
        "id": "x08NRGIbU4j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster.to_csv(\"cluster.csv\")\n",
        "\n",
        "df_cluster.head()\n"
      ],
      "metadata": {
        "id": "CY5IDNgnVRuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"cluster_label\", data=df_cluster)"
      ],
      "metadata": {
        "id": "Ifeh2fUIYkmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Initialize the figure with a logarithmic x axis\n",
        "f, ax = plt.subplots(figsize=(20, 6))\n",
        "#ax.set_xscale(\"log\")\n",
        "\n",
        "\n",
        "# Plot the orbital period with horizontal boxes\n",
        "sns.boxplot(x=\"cluster_label\", \n",
        "            y=\"ltr\", \n",
        "            data=df_cluster,\n",
        "            whis=[0, 100], \n",
        "            width=.6, \n",
        "            palette=\"vlag\")\n",
        "\n",
        "# Add in points to show each observation\n",
        "sns.stripplot(x=\"cluster_label\", \n",
        "              y=\"ltr\", \n",
        "              data=df_cluster,\n",
        "              size=4, \n",
        "              color=\".3\", \n",
        "              linewidth=0)\n",
        "\n",
        "# Tweak the visual presentation\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)"
      ],
      "metadata": {
        "id": "uxIcYxVzV31b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "gPrYLjZsGs90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "GNsFA_adVTcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml = df"
      ],
      "metadata": {
        "id": "ror0Mjoz8mEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml.head()"
      ],
      "metadata": {
        "id": "84DI1nTqG4b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar columnas no relevantes\n",
        "df_ml.drop(['ResponseDate' , 'caseID', 'slaYield', 'caseType', 'severity',  'level3Detected', 'escalation', 'fixType', 'rfoEnabled', 'closeType', 'clarifyName', 'ownerWorkgroup', 'serviceid', 'supportSegment', 'nps_group'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "dIknYpNZPlMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml"
      ],
      "metadata": {
        "id": "ATUlEF6AVhJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X = df_ml.drop('ltr', axis=1)\n",
        "y = df_ml['ltr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de entrenamiento\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X_train)\n",
        "X_train = imputer.transform(X_train)\n",
        "\n",
        "# Escalar las variables de entrada\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Crear un objeto de regresión lineal y ajustar los datos de entrenamiento\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Imputar los valores faltantes en el conjunto de prueba\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Escalar las variables de entrada del conjunto de prueba\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Hacer predicciones con el conjunto de prueba y evaluar el modelo\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "EhEC2ieSVo8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "qlh32sMDVrXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción de LTR"
      ],
      "metadata": {
        "id": "kFR4Ej0ZcmB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Cargar el modelo ya entrenado\n",
        "model = load_model('nombre_del_modelo_entrenado.h5')\n",
        "\n",
        "# Cargar los datos de prueba\n",
        "datos = np.loadtxt('ruta/datos_de_prueba.csv', delimiter=',')\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = MinMaxScaler()\n",
        "datos_escalados = scaler.fit_transform(datos)\n",
        "\n",
        "# Realizar las predicciones\n",
        "predicciones = model.predict(datos_escalados)\n",
        "\n",
        "# Desescalar las predicciones\n",
        "predicciones_desescaladas = scaler.inverse_transform(predicciones)\n",
        "\n",
        "# Imprimir las predicciones\n",
        "print(predicciones_desescaladas)\n"
      ],
      "metadata": {
        "id": "mCQLAZIpcjVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}